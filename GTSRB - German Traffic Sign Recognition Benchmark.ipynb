{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cbe7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Down the kaggle dataset\n",
    "# !curl -L -o gtsrb-german-traffic-sign.zip https://www.kaggle.com/api/v1/datasets/download/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85876083",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"gtsrb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a68a8721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>ShapeId</th>\n",
       "      <th>ColorId</th>\n",
       "      <th>SignId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meta/27.png</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Meta/0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meta/1.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meta/10.png</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meta/11.png</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Path  ClassId  ShapeId  ColorId SignId\n",
       "0  Meta/27.png       27        0        0   1.32\n",
       "1   Meta/0.png        0        1        0   3.29\n",
       "2   Meta/1.png        1        1        0   3.29\n",
       "3  Meta/10.png       10        1        0   3.27\n",
       "4  Meta/11.png       11        0        0   1.22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "nRowsRead = 1000 # specify 'None' if want to read whole file\n",
    "df1 = pd.read_csv(input_dir + '/Meta.csv', delimiter=',', nrows = nRowsRead)\n",
    "df1.dataframeName = 'Meta.csv'\n",
    "nRow, nCol = df1.shape\n",
    "df1.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0bd4798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:53:32.698007: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Libraries \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c391f9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtsrb/train/0/\n",
      "gtsrb/train/1/\n",
      "gtsrb/train/2/\n",
      "gtsrb/train/3/\n",
      "gtsrb/train/4/\n",
      "gtsrb/train/5/\n",
      "gtsrb/train/6/\n",
      "gtsrb/train/7/\n",
      "gtsrb/train/8/\n",
      "gtsrb/train/9/\n",
      "gtsrb/train/10/\n",
      "gtsrb/train/11/\n",
      "gtsrb/train/12/\n",
      "gtsrb/train/13/\n",
      "gtsrb/train/14/\n",
      "gtsrb/train/15/\n",
      "gtsrb/train/16/\n",
      "gtsrb/train/17/\n",
      "gtsrb/train/18/\n",
      "gtsrb/train/19/\n",
      "gtsrb/train/20/\n",
      "gtsrb/train/21/\n",
      "gtsrb/train/22/\n",
      "gtsrb/train/23/\n",
      "gtsrb/train/24/\n",
      "gtsrb/train/25/\n",
      "gtsrb/train/26/\n",
      "gtsrb/train/27/\n",
      "gtsrb/train/28/\n",
      "gtsrb/train/29/\n",
      "gtsrb/train/30/\n",
      "gtsrb/train/31/\n",
      "gtsrb/train/32/\n",
      "gtsrb/train/33/\n",
      "gtsrb/train/34/\n",
      "gtsrb/train/35/\n",
      "gtsrb/train/36/\n",
      "gtsrb/train/37/\n",
      "gtsrb/train/38/\n",
      "gtsrb/train/39/\n",
      "gtsrb/train/40/\n",
      "gtsrb/train/41/\n",
      "gtsrb/train/42/\n"
     ]
    }
   ],
   "source": [
    "# Reading the input images and putting them into a numpy array\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "height = 30\n",
    "width = 30\n",
    "channels = 3\n",
    "classes = 43\n",
    "n_inputs = height * width*channels\n",
    "\n",
    "for i in range(classes) :\n",
    "    path = input_dir + \"/train/{0}/\".format(i)\n",
    "    print(path)\n",
    "    Class=os.listdir(path)\n",
    "    for a in Class:\n",
    "        try:\n",
    "            image=cv2.imread(path+a)\n",
    "            image_from_array = Image.fromarray(image, 'RGB')\n",
    "            size_image = image_from_array.resize((height, width))\n",
    "            data.append(np.array(size_image))\n",
    "            labels.append(i)\n",
    "        except AttributeError:\n",
    "            print(\" \")\n",
    "            \n",
    "Cells=np.array(data)\n",
    "labels=np.array(labels)\n",
    "\n",
    "#Randomize the order of the input images\n",
    "s=np.arange(Cells.shape[0])\n",
    "np.random.seed(43)\n",
    "np.random.shuffle(s)\n",
    "Cells=Cells[s]\n",
    "labels=labels[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46629c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Spliting the images into train and validation sets\n",
    "(X_train,X_val)=Cells[(int)(0.2*len(labels)):],Cells[:(int)(0.2*len(labels))]\n",
    "X_train = X_train.astype('float32')/255 \n",
    "X_val = X_val.astype('float32')/255\n",
    "(y_train,y_val)=labels[(int)(0.2*len(labels)):],labels[:(int)(0.2*len(labels))]\n",
    "\n",
    "#Using one hote encoding for the train and validation labels\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 43)\n",
    "y_val = to_categorical(y_val, 43)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9adee4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sp/.venv/lib/python3.13/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-10-30 11:59:14.188194: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-10-30 11:59:14.190465: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:171] verbose logging is disabled. Rerun with verbose logging (usually --v=1 or --vmodule=cuda_diagnostics=1) to get more diagnostic output from this module\n",
      "2025-10-30 11:59:14.190496: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:176] retrieving CUDA diagnostic information for host: p200300d297192600016b623367354e87.dip0.t-ipconnect.de\n",
      "2025-10-30 11:59:14.190522: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:183] hostname: p200300d297192600016b623367354e87.dip0.t-ipconnect.de\n",
      "2025-10-30 11:59:14.190720: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:190] libcuda reported version is: 470.256.2\n",
      "2025-10-30 11:59:14.190827: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:194] kernel reported version is: 470.256.2\n",
      "2025-10-30 11:59:14.190843: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:284] kernel version seems to match DSO: 470.256.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Definition of the DNN model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax'))\n",
    "\n",
    "#Compilation of the model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76f610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:59:47.844792: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 338774400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m980/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4116 - loss: 2.1870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 12:00:38.950426: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 84682800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m981/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 52ms/step - accuracy: 0.6541 - loss: 1.2247 - val_accuracy: 0.9597 - val_loss: 0.1555\n",
      "Epoch 2/20\n",
      "\u001b[1m918/981\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9149 - loss: 0.2779"
     ]
    }
   ],
   "source": [
    "#using ten epochs for the training and saving the accuracy for each epoch\n",
    "epochs = 20\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=epochs,validation_data=(X_val, y_val))\n",
    "\n",
    "#Display of the accuracy and the loss values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(history.history['acc'], label='training accuracy')\n",
    "plt.plot(history.history['val_acc'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
